-----

## Motivation

sequence of observations $X_1, \dots, X_T$
- index $t$: time, location, ...
- for now: cont observation at discrete time steps
- example: time-series dorecasting in weather, economics,...

> observations are not independent → non-i.i.d data


## Definition

> $AR(p)$ of order $p$:
> $$ X_t = c + \sum_{i=1}^p \varphi_i X_{t-i} + \epsilon_t$$ where $\varphi_i$ are parameters, $\epsilon\sim N(0, \sigma)$ is **white noise** and $X_{t-i}$ is the **lagged value** at time $i$

- linear regression
- **auto**regressive: previous outputs/lags as inputs
- every time point affects all future time points → no independence
- $\varphi$ and $c$ are **shared through time**

rewrite as probabilistic model:
$$P(X_t \mid X_{t-1}, \dots, X_{t-p}) \sim N(c+\sum^p_{i=1} \varphi_i X_{t-i}, \sigma)$$

##### Mean function of an AR model
$$\mu(t) = E[X_t]$$

##### Autocovariance
$$\gamma(t, i) = Cov(X_t, X_{t-1})$$

##### Pearson autocorrelation function
$$\rho(t,i) = \frac{Cov(X_t, X_{t-i})}{\sqrt{Var(X_t)}\sqrt{Var(X_{t-i})}} \in [0,1]$$
→ shows e.g. seasonalities

#### Variance and autoregression

- usually, "x-distance" is relevant for whether variance is low or high
	- is the known data far in the past?
- with autoregression, "y-distance" is more important
	- have we seen similar data before?


## Parameter Learning

least squares regression:
$$...=(X^TX)^{-1}X^Ty$$
where
$$X=$$
and $$y = $$


## Data split

**must** be according to time
→ test only on future values

-----
## Stationarity

> a **stationary** process...
> 1. has a constant mean function: $E[X_t] = E[X_{t-i}] \forall t, i$
> 2. has an autocovariance that depends only on the lagged value, not $t$: $Cov(X_t, X_{t-i}) = \gamma_i \forall t, i$, this also means: $\gamma_i = Cov(X_t, X_{t-i}) = Cov(X-{t-i}, X_t) = \gamma_{-i}$
> 3. $E[|X_t|^2] < \infty\>\forall t$

- good modeling assumption (like i.i.d)
- estimate mean/autocovariance by estimating over time: generalize to future!###

#### Using Stationarity to learn parameters:


-----
## Markov Chains

> **Markov chain**: sequence of random variables $X_1, X_2, \dots, X_T$ with the **Markov property**: $$P(X_t | X_{1}, \dots, X_{t-1}) = P(X_t | X{t-1})$$
> where $t$ and $X_i$ are discrete.
> 