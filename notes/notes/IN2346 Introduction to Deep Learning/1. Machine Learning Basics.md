----

##### Context
methods: AI, ML, DL
tasks: eg image classification

#### A simple task: Image Classification
- given images, assign a class label → **mapping**
- challenges/added complexities: 
	- occlusions: pictures map 3D into 2D, but not bijectively
	- background clutter
	- everything happening in the visualization pipeline (pose, illumination, appearance)
- representation: set of pixels


#### A simple classifier: #kNN

>**nearest neighbor**: compare representations using a distance functions, then assign class label of closest (known)
>
>**k-nearest neighbor**/**k-NN**: for robustness, let the $k$ nearest neighbors vote

relevant questions:
1. classifier performance on training data?
	- perfect performance if all data would be known
2. what classifier is more likely to perform best on test data?
	- up to a point: larger $k$ better
	- sanity check: we want to do better than the majority class
		- bc a naive approach would be correct for percentage of majority class 
3. what are we actually learning?
	- not a network, not weights, hmmmm.... 

k-NN hyperparameters:
- distance function: L1 distance, L2 distance, etc
- number of neighbors $k$
→ problem-dependent; how to choose? we learn, yay!

----

## ML for Classification

![[classification.svg]]

#### Mathematical formulation (high-level)
$$M_{\theta}(I)= \{\text{DOG}, \text{CAT}\}$$where $M$ model, $\theta$ model parameters, $I$ image, rhs class labels

parameter learning:$$\theta^{*} = \arg\min_\theta \sum\limits_{i} D(M_\theta(I_{i}) - Y_{i})$$for some distance function $D$
- we try to find an optimal solution that explains the training data
- then we want it to generalize well!

### Basic Recipe for Machine Learning

data split: 
![[data-split.svg]]

main components:
- task
- experience (data)
- performance measure

### Overview: Machine Learning

>**unsupervised learning**: no labels/target classes (aka not necessarily a semantic meaning), instead find out properties of structure of data
>e.g. #clustering

>**supervised learning**: labels or taget classes

→ do humans learn in a supervised or unsupervised way?

>**reinforcement learning**: agents interact with environment and receive feedback/reward

→ kinda inbetween?

>**regression**: predict continuous output value

>**classification**: predict a discrete value → either binary or multi-class

----

## Linear Decision Boundaries

- fit a hyperplane into the data space
- very simplistic tho

-----

## Linear Regression

- supervised learning
- find a linear model that explains a target $y$ given inputs $x$

training:
![[trainingLR.svg]]
testing:
![[testingLR.svg]]
→ we want to predict the right $\hat{y}$ for a new $x$!

### Mathematical formulation
#linearmodel :$$\hat{y}_{i} = \sum\limits_{j=1}^{d}x_{ij}\theta_{j}$$with 
- input dimension $d$
- input data/features $x_{ij}$ → we can have many features!
- weights $\theta_{j}$ 

usually, a bias is added:$$\hat{y}_{i} = \theta_{0} + \sum\limits_{j=1}^{d}x_{ij}\theta_{j}$$
### Linear prediction
weights in a system of linear equations: $$\begin{bmatrix}
\hat{y}_{1} \\ \hat{y}_{2} \\ \vdots \\ \hat{y}_{n}\end{bmatrix} = \begin{bmatrix}
1  & x_{11} & \cdots  &  x_{1d} \\
1 & x_{21} & \cdots & x_{2d}  \\ 
\vdots  &  \vdots  & \ddots  & \vdots \\ 1 & x_{n1} & \cdots & x_{nd}\end{bmatrix}\begin{bmatrix}
\theta_{0} \\ \theta_{1} \\ \vdots \\ \theta_{d}\end{bmatrix}$$or in short $$\hat{y}=X \theta$$where 
- each row in $X$ represents a $d$-dimensional **feature vector**
- $\theta_{0}$ is a general bias, while the other $\theta_{i}$ are each associated with a specific feature

### How to obtain the model
![[learning.svg]]

>**loss function**: measures quality of estimation and tells optimization how to improve estimate

>**optimization**: changes model to improve loss function

### Linear Least Squares #LLS
approach to fit linear model to the data $$\min_{\theta}J(\theta) = \frac{1}{n} \sum\limits_{i=1}^{n}(\hat{y}_{i} - y_{i})^{2}$$or in terms of the components of a linear model: $$\frac{1}{n}\sum\limits_{i=1}^{n} (x_{i}\theta-y_{i})^{2}$$and in matrix notation: $$\min_{\theta} J(\theta) = (X \theta - y)^{T}(X \theta - y)$$
- dimensions: $n$ training samples where each input vector has size $d$
- not the best, but the simplest estimate

##### Analytical solution
set gradient to $0$: $$\begin{align*}
\frac{\partial J(\theta)}{\partial \theta} &= 2X^{T}X \theta - 2X^{T}y = 0\\
\theta &= (X^{T}X)^{-1}X^{T}y
\end{align*}$$
### Maximum Likelihood Estimate #MLE
assumption: underlying distribution belongs to a parametric family of distributions
![[model_and_obs.svg]]
→ estimation by finding parameter values that **maximize likelihood** of observations: $$\theta_{ML} = \arg \max_{\theta} p_{model}(y \mid X, \theta)$$
>MLE assumes that the training samples are **independent and generated by the same probability distribution** ("independently and identically distributed" or #iid) $$p_{model}(y \mid X, \theta) = \prod_{i=1}^{n} p_{model}(y_{i} \mid x_{i}, \theta)$$

and bc logarithms make pretty sums that are easier to deal with: $$\theta_{ML} = \arg \max_{\theta} \sum\limits_{i=1}^{n} \log p_{model}(y_{i}\mid x_{i}, \theta)$$
### Use in Linear Regression
we need the conditional probability distribution $(y_{i} \mid x_{i}, \theta)$ for MLE

1. we assume a Gaussian/Normal distribution for the $y_{i}$: $$y_{i} \sim \mathcal{\mu, \sigma^{2}} = \mathcal{N}(x_{i}\theta, \sigma^{2}) = x_{i}\theta + \mathcal{N}(0, \sigma^{2})$$
2. the Gaussian probability density function is given by: $$p(y_{i}) = \frac{1}{\sqrt{2\pi\sigma^{2}}} e^{-\frac{1}{2\sigma^{2}} (y_{i}- \mu )^{2}}$$
and so we have $$p(y_{i} \mid x_{i}, \theta) = (2\pi \sigma^{2})^{-\frac{1}{2}} e^{-\frac{1}{2\sigma^{2}} (y_{i}-x_{i}\theta)^{2}}$$
which becomes a lot easier to read after inserting it into the MLE formula with the logarithm: $$\sum\limits_{i=1}^{n} - \frac{1}{2} \log (2\pi\sigma^{2}) + \sum\limits_{i=1}^{n} \left(-\frac{1}{2\sigma^{2}} \right)(y_{i}-x_{i}\theta)^{2}$$and even better in matrix notation: $$-\frac{n}{2} \log(2\pi\sigma^{2}) - \frac{1}{2\sigma^{2}} (y-X\theta)^{T}(y-X \theta)$$which is now the point where we try to find the estimate of $\theta$

----

## Logistic Regression

##### Sigmoid function
maps continuous values onto $[0, 1]$ which can be interpreted as probabilities:  #sigmoid$$\sigma(x) = \frac{1}{1 + e^{-x}}$$→ can be interpreted as a 1-layer neural network

### Probability of binary output
we focus on $y=1$: $$\hat{y} = p(y=1 \mid X, \theta) = \prod_{i=1}^{n} p(y_{i}=1 \mid x_{i}, \theta)$$
relates to Bernoulli trial! → how? $$p(z \mid \phi) = \phi^{z}(1-\phi)^{1-z} = \begin{cases}
\phi & z=1 \\
1-\phi & z=0
\end{cases}$$and $$\hat{y} = \prod_{i=1}^{n} \textcolor{Periwinkle}{\hat{y}_{i}}^{y_{i}} (1-\hat{y}_{i})^{(1-\textcolor{Orchid}{y_{i}})}$$where
- $\hat{y}_{i}$ continuous prediction of sigmoid
- $y_{i}$ true labels, aka 0 or 1

### Loss function for the logistic regression
when inserting into the MLE formula, the probability of the binary output $$p(y \mid X, \theta) = \hat{y} = \prod_{i=1}^{n} \hat{y}_{i}^{y_{i}} (1-\hat{y}_{i})^{(1-y_{i})}$$will be subjected to the logarithm, which turns it into (note that this is now a minimization problem)$$-\sum\limits_{i=1}^{n} y_{i}\log \hat{y}_{i} + (1-y_{i}) \log(1-\hat{y}_{i})$$ and thus, we arrive at the **binary cross-entropy** function #bce which is related to the #softmax $$\mathcal{L}(\hat{y}_{i}, y_{i}) = - [y_{i} \log \hat{y}_{i} + (1 - y_{i})\log(1 - \hat{y}_{i})]$$
- if $y_{i}=1$, we want to maximize $\log\hat{y}_i$ and therefore also $\hat{y}_i$, because: $$\mathcal{L}(\hat{y}_{i,}1) = \log \hat{y}_i$$
- if $y_{1}=0$, we want to maximize $\log (1-\hat{y}_i)$$ and therefore minimize $\hat{y}_i$, because: $$$\mathcal{L}(\hat{y}_{i},0) = \log (1-\hat{y}_i)$$
### Optimizing Logistic Regression
from the loss function $$\mathcal{L}(\hat{y}_{i}, y_{i}) = - [y_{i} \log \hat{y}_{i} + (1 - y_{i})\log(1 - \hat{y}_{i})]$$we get the corresponding **cost function** $$\begin{align*}
C(\theta) &= -\frac{1}{2} \sum_{i=1}^{n} \mathcal{L}(\hat{y}_i, y_{i}) \\
&= -\frac{1}{2} \sum_{i=1}^{n} y_{i} \log \hat{y}_{i} + (1 - y_{i})\log(1 - \hat{y}_{i})
\end{align*}$$
- mean of loss across 2 classes
- no closed-form solution → we will use #gradientdescent