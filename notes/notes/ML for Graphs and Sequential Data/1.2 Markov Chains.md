----

> **Markov chain**: sequence of random variables $X_1, X_2, \dots, X_T$ with the **Markov property**: $$P(X_t | X_{1}, \dots, X_{t-1}) = P(X_t | X{t-1})$$
> where $t$ and $X_i$ are discrete.

[TODO: until slide 13]

## Other Fun Stuff to do with MCs

##### Probability of getting from $i$ to $j$ in $n$ steps
recursive function $$A_{ij}(n) = P(X_{t=n}=j\mid X_t = i) = \sum^K_{k=1} A_{kj}A_{ik}(n-1)$$or in matrix form $$A(n) = A(n-1)A$$which in combination with $A(1)=A$ gives us $$A(n)=A^n$$and we arrive at the **Chapman-Kolmogorov** equations: $$A_{ij}(m+n)=\sum^K_{k=1} A_{ik}(m)A_{kj}(n)$$or $$A(m+n)=A(m)+A(n)$$
##### Probability of reaching state $j$ in step $t$
[TODO]