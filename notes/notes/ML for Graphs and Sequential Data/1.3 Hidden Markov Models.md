----

#### Motivation

- basic AR models and MC are VERY simple - too simple
- now: probabilistic latent variable models for sequences of observations

1. Markov property is not realistic
	- eg: NLP often has long-range dependencies
2. states are often not known and can only be observed indirectly
	- measurements may be noisy and a subset of the 'true' sequence

>while the true, unobserved states may fully describe the situation to the point of having the Markov property, the indirect measurements often do not

----

## Definition

>**Hidden Markov Model**: sequence of **hidden variables** $[Z_1,\dots,Z_T]$ and sequence of **observed variables** $[X_1,\dots,X_T]$ s.t. the $Z_1, \dots, Z_T$ satisfy Markov property: $$P(Z_{t+1} \mid Z_t, Z_{t-1}... TODO)$$and the distribution of X_t depends only on Z_t:$$TODO$$
>$P$ is called a **transition probability** and $P$ is called an **emission probability**

convention: discrete time $t$ and discrete $Z_t$

graphical model:


joint distribution:


##### Discrete Case: $X_t \in \{1, 2, \dots, K'\}$
probabilities can be described as matrices:
but number of parameters is still very high:


##### Parameter Tying
TODO


----

## Tasks

1. **inference**: from fixed model parameters, find info from posterior distribution $\Pr(Z-{1:T} \mid X_{1:T})$
2. **parameter learning**: learn model parameters from observed $X_{1:T}$

### Inference

1. **filtering**: compute current time step given sequence up to that point - online setting!
2. **smoothing**: compute a time step given the whole sentence
3. **MAP inference**: compute most likely sequence of hidden states
	- also known as Viterbi decoding
	- might be different from individual filtering!
	- only gives sequence, not the distribution/probability

> the most likely sequence != sequence of most likely states 

e.g. probability of 'that' vs probability of 'that that'

#### Filtering: Forwards Algorithm
goal: compute $P(Z_t \mid X_{1:t})$

thoughts:
TODO

→ we compute $\alpha_1$ :$$a_1(k)=\pi_k B_{kx_{1}}$$ and then $\alpha_{t+1}$ recursively from $\alpha_t$:$$\alpha_{t+1}(k) = B_{k(x_{t+1})}\sum^K_{j=1} A_{jk}\alpha_t(j))$$or in matrix notation:$$\alpha_{t+1} = B_{} \circ (A^T\alpha_t)$$which takes $\mathcal{O}(TK^2)$ time

#### Smoothing: Forward-Backwards Algorithm
goal:

thoughts:

→ we initialize $\beta_T$: $$\beta_T(k)=1$$and then $\beta_t$ from $\beta_{t+1}$

#### MAP inference in HMMs
goal:$$\begin{align*}&\arg \max_Z P(Z_{1:T}\mid X_{1:T})\\ = &\arg \max_Z \log P(Z_{1:T}\mid X_{1:T})\\ = &\arg\max_Z TODO\end{align*}$$where each term depends on values of $Z_{t-1}$ and $Z_t$

→ bipartite graph with weights between time steps

shortest-path problem:
